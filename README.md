# THIS REPO IS STILL A WORK IN PROGRESS 
### Things might break.


# BCI AIC3 Deep Learning Pipeline


The code in this repo is for the AIC3 competition.

The goal of this code is to serve as a full pipeline for data loading, preprocessing, model training, evaluation and inference, while being modular and giving reproducible results given the same inputs and configurations.

****

## Problem Statement

Given raw EEG signal readings from two tasks Motor-Imagery (MI) and Steady-State Visual Evoked Potential (SSVEP), the goal is to classify the signal to the correct class.

- MI: (Left, Right)
 
- SSVEP: (Left, Right, Forward, Backward)

****

## Repository Structure

```
├── LICENSE
├── README.md
├── configs
│   ├── label_mappings              # for encoding the labels
│   │   ├── label_mapping.json
│   │   └── reverse_label_mapping.json
│   ├── mi_config.yaml
│   └── ssvep_config.yaml
│
├── data                            # data directory structure (not uploaded to github)
│   ├── interim
│   ├── processed                   # processed data directory (.npy for fast loading)
│   │   ├── MI
│   │   │   ├── train_data.npy
│   │   │   ├── train_labels.npy
│   │   │   ├── validation_data.npy
│   │   │   └── validation_labels.npy
│   │   └── SSVEP
│   │       ├── train_data.npy
│   │       ├── train_labels.npy
│   │       ├── validation_data.npy
│   │       └── validation_labels.npy
│   └── raw
│       ├── MI
│       ├── README.md
│       ├── SSVEP
│       ├── mtcaic3.zip
│       ├── sample_submission.csv
│       ├── test.csv
│       ├── train.csv
│       └── validation.csv
│
├── notebooks                       # notebooks for experimentation and testing (messy)
│   ├── aic3_test1_messy.ipynb
│   ├── data_preprocessing.ipynb
│   ├── lightning_trainer.ipynb
│   ├── preprocessing_notebook.html
│   ├── preprocessing_notebook.ipynb
│   ├── preprocessing_pipeline.ipynb
│   └── simple_cnn_training_both.ipynb
│
├── pyproject.toml
├── requirements-dev.lock
├── requirements.lock
│
├── results
│   ├── figures            
│   └── logs
│
├── run
│   ├── MI
│   │   └── EEGNet-f1-0.4318-20250624_033254
│   │       ├── weights.pt  
│   │       ├── config.yaml 
│   │       └── checkpoints/
│   └── SSVEP
│       └── EEGNet-f1-0.2717-20250624_033202
│           ├── weights.pt  
│           ├── config.yaml 
│           └── checkpoints/
│
├── scripts                       
│   ├── make_labels.py              # loads 2 models and uses them to make an OUTPUT_FILE.csv file
│   └── preprocess_data.py          # preprocess the data and store in data/processed/
│
├── src
│   └── bci_aic3
│       ├── __init__.py
│       ├── config.py               # config definitions and config loading
│       ├── data.py                 # BCIDataset, and data loading
│       ├── inference.py            # inference methods and functions
│       ├── models                  # torch models 
│       ├── paths.py                # paths defined with respect to PROJECT_ROOT
│       ├── preprocess.py           # data preprocessing, filters, cropping
│       ├── train.py                # pytorch lightning trainer and lightning
│       └── util.py                 # various utility scripts
│
├── submissions                     # kaggle submissions folder (not on github)
│   └── submissions.csv             # csv files generated by scripts/make_labels.py go here
│
├── training_stats                  # training means and stds used for normalization of validation and test data
│   ├── mi_stats.pt
│   └── ssvep_stats.pt
│
└── uv.lock
```


## Methodology

- ### Preprocessing
    TODO: filtering, ffts, down-sampling, etc...

    - Notch filtering at 50Hz.
    - Bandpass filtering depending on task_type [`lfreq`, `hfreq`].
    - Using the first second as a baseline and subtracting its mean from the data.
    - Cropping the range [`tmin`, `tmax`].

- ### Architecture 
    TODO: EEGNet

- ### Evaluation
    TODO: Average F1 score of 2 models 


## Environment setup

If you don't have `uv` I reccommend installing it as that'll save you a lot of trouble and it's just a one line install.

```sh
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```


```powershell
# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

Make sure it installed correctly and added to path:
```
uv --version
```
Note: if the code above doesn't return the version add uv to your path manually.
****

Now clone this repo and cd into it:
```sh
git clone https://github.com/Mohamed-Badry/bci_aic3.git
cd bci_aic3
```

And to get your `.venv` set up 
```sh
uv sync
```

Finally to install this package and be able to import from it:
```sh
# run this if you want to install the package in editable mode
uv pip install -e .
```

```sh
# run this if you want to install it in non-editable mode
uv pip install . --no-deps
```
****


## Usage

#### TODO: Script to run it all end to end.


### Preprocessing

To preprocess the MI training and validation data 
```sh
uv run scripts/preprocess_data.py --task_type MI 
```

The same goes for SSVEP
```sh
uv run scripts/preprocess_data.py --task_type SSVEP 
```

These scripts both apply the `preprocessing_pipeline()` function defined in `src/bci_aic3/preprocess.py` (subject to change) to the training and validation data using parameters defined in the `configs/` file, and store them in the `data/processed/` directory.

****

### Training

To train the MI model.
```sh
uv run -m bci_aic3.train --task_type MI
```

And the same goes for SSVEP
```sh
uv run -m bci_aic3.train --task_type SSVEP
```

Both the preprocessing and training use a default `CONFIG_PATH` in `src/bci_aic3/paths.py` and the defaults point to yaml files in `configs/` which you can edit before each run.

Training the models creates unique directories in the `run/` directory with each one storing the model checkpoints and when the training is finished the config file and final weights are saved to the same directory. This allows for easy tracking of models and which config file generated them. 

Note: The unique folders have their names formatted like so `run/{TASK_TYPE}/EEGNet-f1-{val_f1}-{timestamp}` and the `weights.pt` file stored in them is saved as torchscript, which means it should be loaded using `torch.jit.load()` if it were to be used outside this project, and it can be loaded to other torch runtimes that support torchscript too.

#### Config File Structure
```yaml
# model config
model:
  name: "EEGNet"
  task_type: "MI"
  num_classes: 2
  sequence_length: 2250
  num_channels: 8

# training config
training:
  epochs: 100
  batch_size: 128
  learning_rate: 0.001

# preprocessing settings
preprocessing:
  notch_freq: 50.0
  lfreq: 6.0
  hfreq: 32.0
  baseline: [0.0, 1.0]
  tmin: 2.0
  tmax: 8.0
  sfreq: 250.0
  scaling_factor: 1.0e-6
```