{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deef180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bci_aic3.config import load_processing_config\n",
    "from bci_aic3.paths import LABEL_MAPPING_PATH, MI_CONFIG_PATH\n",
    "from bci_aic3.util import read_json_to_dict\n",
    "\n",
    "from bci_aic3.data import load_raw_data\n",
    "from bci_aic3.paths import RAW_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14141051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processing_config = load_processing_config(MI_CONFIG_PATH)\n",
    "label_mapping = read_json_to_dict(LABEL_MAPPING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb425d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [02:10<00:00, 18.39it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 17.55it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 18.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train, val, _ = load_raw_data(\n",
    "    base_path=RAW_DATA_DIR,\n",
    "    task_type=\"MI\",\n",
    "    label_mapping=label_mapping,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd535a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from mne.preprocessing import ICA\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bci_aic3.config import ProcessingConfig\n",
    "from bci_aic3.data import BCIDataset\n",
    "from bci_aic3.paths import PROCESSED_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a1f1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIBCIPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A preprocessing pipeline for Motor Imagery BCI.\n",
    "\n",
    "    This pipeline applies the following steps:\n",
    "    1. Converts NumPy array to MNE EpochsArray.\n",
    "    2. Applies a notch filter to remove powerline noise.\n",
    "    3. Applies a custom Butterworth bandpass filter.\n",
    "    4. Fits and applies ICA to remove biological artifacts.\n",
    "    5. Crops the epochs to the time window of interest.\n",
    "    6. Fits and applies Common Spatial Patterns (CSP) for feature extraction.\n",
    "\n",
    "    The output is ready for a classification model like EEGNet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ProcessingConfig):\n",
    "        self.config = config\n",
    "        self.ica = None\n",
    "        self.csp = None\n",
    "        self.info = None\n",
    "\n",
    "    def _create_mne_epochs(self, X: np.ndarray) -> mne.EpochsArray:\n",
    "        \"\"\"Creates an MNE EpochsArray object from a NumPy array.\"\"\"\n",
    "        if self.info is None:\n",
    "            self.info = mne.create_info(\n",
    "                ch_names=self.config.ch_names, sfreq=self.config.sfreq, ch_types=\"eeg\"\n",
    "            )\n",
    "            montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "            self.info.set_montage(montage, on_missing=\"ignore\")\n",
    "\n",
    "        tmin_original = 0\n",
    "        return mne.EpochsArray(X, self.info, tmin=tmin_original, verbose=False)\n",
    "\n",
    "    def _apply_filters(self, epochs: mne.EpochsArray) -> mne.EpochsArray:\n",
    "        \"\"\"Applies notch and bandpass filters to the data array.\"\"\"\n",
    "        # Get data as a NumPy array to apply filters\n",
    "        data = epochs.get_data(copy=True)\n",
    "\n",
    "        # 1. Notch Filter using the top-level MNE function\n",
    "        data_notched = mne.filter.notch_filter(\n",
    "            data,\n",
    "            Fs=self.config.sfreq,\n",
    "            freqs=self.config.notch_freq,\n",
    "            method=\"iir\",  # IIR is generally faster for notch\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # 2. Bandpass Filter (using a zero-phase Butterworth filter)\n",
    "        b, a = butter(  # type: ignore\n",
    "            self.config.filter_order,\n",
    "            [self.config.bandpass_low, self.config.bandpass_high],\n",
    "            btype=\"bandpass\",\n",
    "            fs=self.config.sfreq,\n",
    "        )\n",
    "\n",
    "        # Apply the filter forward and backward to each channel and epoch\n",
    "        data_bandpassed = filtfilt(b, a, data_notched, axis=-1)\n",
    "\n",
    "        # Create a new EpochsArray with the filtered data\n",
    "        epochs_filtered = mne.EpochsArray(\n",
    "            data_bandpassed, epochs.info, tmin=epochs.tmin, verbose=False\n",
    "        )\n",
    "        return epochs_filtered\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Fits the ICA and CSP transformers on the training data.\n",
    "\n",
    "        Args:\n",
    "            X: EEG data, shape (n_epochs, n_channels, n_times)\n",
    "            y: Labels, shape (n_epochs,)\n",
    "        \"\"\"\n",
    "        # --- Step 1: Create MNE object and apply basic filters ---\n",
    "        epochs = self._create_mne_epochs(X)\n",
    "        epochs_filtered = self._apply_filters(epochs)\n",
    "\n",
    "        # --- Step 2: Fit ICA for artifact removal ---\n",
    "        self.ica = ICA(\n",
    "            n_components=self.config.ica_n_components,\n",
    "            random_state=self.config.ica_random_state,\n",
    "            max_iter=\"auto\",\n",
    "        )\n",
    "        self.ica.fit(epochs_filtered)\n",
    "\n",
    "        # --- Step 3: Apply ICA and Crop Epochs ---\n",
    "        epochs_ica = self.ica.apply(epochs_filtered.copy(), verbose=False)\n",
    "        epochs_cropped = epochs_ica.copy().crop(\n",
    "            tmin=self.config.tmin, \n",
    "            tmax=self.config.tmax,\n",
    "            include_tmax=False,\n",
    "        )\n",
    "\n",
    "        # --- Step 4: Fit CSP ---\n",
    "        self.csp = CSP(\n",
    "            n_components=self.config.n_csp_components,\n",
    "            reg=None,\n",
    "            log=None, \n",
    "            norm_trace=False,\n",
    "            transform_into='csp_space',\n",
    "        )\n",
    "        self.csp.fit(epochs_cropped.get_data(), y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies the learned transformations (ICA, CSP) to the data.\n",
    "\n",
    "        Args:\n",
    "            X: EEG data, shape (n_epochs, n_channels, n_times)\n",
    "\n",
    "        Returns:\n",
    "            Spatially filtered time-series data, shape (n_epochs, n_csp_components, n_cropped_times)\n",
    "        \"\"\"\n",
    "        if self.ica is None or self.csp is None:\n",
    "            raise RuntimeError(\n",
    "                \"The preprocessor has not been fitted yet. Call fit() first.\"\n",
    "            )\n",
    "\n",
    "        # --- Step 1 & 2: Create MNE object and apply filters ---\n",
    "        epochs = self._create_mne_epochs(X)\n",
    "        epochs_filtered = self._apply_filters(epochs)\n",
    "\n",
    "        # --- Step 3: Apply fitted ICA ---\n",
    "        epochs_ica = self.ica.apply(epochs_filtered, verbose=False)\n",
    "\n",
    "        # --- Step 4: Crop to time window of interest ---\n",
    "        epochs_cropped = epochs_ica.crop(tmin=self.config.tmin,\n",
    "                                         tmax=self.config.tmax, \n",
    "                                         include_tmax=False)\n",
    "\n",
    "        # --- Step 5: Apply fitted CSP to get spatially filtered time series ---\n",
    "        eegnet_input = self.csp.transform(epochs_cropped.get_data())\n",
    "\n",
    "        return eegnet_input.astype(np.float32)\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        \"\"\"Fit to data, then transform it.\"\"\"\n",
    "        return self.fit(X, y).transform(X)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "843d1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing_pipeline(\n",
    "    train_dataset: BCIDataset,\n",
    "    validation_dataset: BCIDataset,\n",
    "    task_type: str,\n",
    "    processing_config: ProcessingConfig,\n",
    "):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=len(train_dataset), shuffle=False\n",
    "    )\n",
    "    train_data, train_labels = next(iter(train_loader))\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        validation_dataset, batch_size=len(validation_dataset), shuffle=False\n",
    "    )\n",
    "    val_data, val_labels = next(iter(val_loader))\n",
    "\n",
    "    train_data = train_data.numpy()\n",
    "    train_labels = train_labels.numpy()\n",
    "\n",
    "    val_data = val_data.numpy()\n",
    "    val_labels = val_labels.numpy()\n",
    "\n",
    "    preprocessor = MIBCIPreprocessor(processing_config)\n",
    "\n",
    "    train_data_processed = preprocessor.fit_transform(train_data, train_labels)\n",
    "\n",
    "    val_data_processed = preprocessor.transform(val_data)\n",
    "\n",
    "    # Define the directory where the files will be saved\n",
    "    output_dir = PROCESSED_DATA_DIR / task_type.upper()\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save processed training data and labels\n",
    "    processed_train_data_path = output_dir / \"train_data.npy\"\n",
    "    processed_labels_path = output_dir / \"validation_labels.npy\"\n",
    "\n",
    "    np.save(processed_train_data_path, train_data_processed)\n",
    "    print(f\"Processed data successfully saved at: {processed_train_data_path}\")\n",
    "    np.save(processed_labels_path, train_labels)\n",
    "    print(f\"Processed labels successfully saved at: {processed_labels_path}\")\n",
    "\n",
    "    # Save processed validation data and labels\n",
    "    processed_val_data_path = output_dir / \"validation_data.npy\"\n",
    "    processed_labels_path = output_dir / \"validation_labels.npy\"\n",
    "\n",
    "    np.save(processed_val_data_path, val_data_processed)\n",
    "    print(f\"Processed data successfully saved at: {processed_val_data_path}\")\n",
    "\n",
    "    np.save(processed_labels_path, val_labels)\n",
    "    print(f\"Processed labels successfully saved at: {processed_labels_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75066611",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_config = load_processing_config(MI_CONFIG_PATH)\n",
    "label_mapping = read_json_to_dict(LABEL_MAPPING_PATH)\n",
    "task_type = \"MI\"\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train, batch_size=len(train), shuffle=False,\n",
    ")\n",
    "train_data, train_labels = next(iter(train_loader))\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val, batch_size=len(val), shuffle=False,\n",
    ")\n",
    "val_data, val_labels = next(iter(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d572ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = train_data.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "\n",
    "val_data = val_data.numpy()\n",
    "val_labels = val_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e07092b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 8, 2250), (2400,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "095651e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 8, 2250), (50,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "054f8637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbadr\\AppData\\Local\\Temp\\ipykernel_22452\\2849712291.py:83: RuntimeWarning: The data has not been high-pass filtered. For good ICA performance, it should be high-pass filtered (e.g., with a 1.0 Hz lower bound) before fitting ICA.\n",
      "  self.ica.fit(epochs_filtered)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 8 components\n",
      "Fitting ICA took 79.3s.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 8.5e+02 (2.2e-16 eps * 8 dim * 4.8e+17  max singular value)\n",
      "    Estimated rank (data): 8\n",
      "    data: rank 8 computed from 8 data channels with 0 projectors\n",
      "Reducing data rank from 8 -> 8\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "preprocessor = MIBCIPreprocessor(processing_config)\n",
    "\n",
    "train_data_processed = preprocessor.fit_transform(train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "437f3b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 6, 750)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7bcb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_processed = preprocessor.transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0de1c925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6, 750)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9bb7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
